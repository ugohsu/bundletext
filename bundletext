#!/usr/bin/env python3
"""
bundletext: Bundle (mostly) all non-binary files under given paths into one text file for LLM ingestion.

Features
- Collects (mostly) all text files under given roots into one bundle text file.
- Respects .gitignore by default (basic subset; can be disabled with --no-gitignore).
- Exclusions:
  - directory names, file names, glob patterns, explicit paths, path substring.
  - Additive by default: built-in defaults + user additions.
  - Escape hatch to disable built-in defaults: --no-default-exclude-*
- Symlinks:
  - Optional follow: --follow-symlinks
  - Cycle protection (realpath-based) and de-dup of identical targets
- Binary detection:
  - UTF-8-first heuristic (robust for Japanese text)
  - Can be disabled with --no-binary-check
- Big files:
  - --max-bytes with --big-file {skip,truncate} and --truncate-bytes
- Tree:
  - Default behavior: Project Tree includes ONLY files actually bundled ("tree-only-included" default)
- Dry-run:
  - --dry-run prints a report showing which files would be included vs skipped (with reasons).
    It also prints:
      * Candidate Tree: after excludes/.gitignore (before binary/size/readability checks)
      * Project Tree  : included-only (same as real output)

Output format
- The bundle contains:
  1) AI instructions
  2) Project Tree (optional)
  3) File contents, separated by FILE_PATH headers
"""

from __future__ import annotations

import argparse
import datetime
import fnmatch
import os
import sys
from dataclasses import dataclass
from enum import Enum
from typing import Dict, Iterable, List, Optional, Sequence, Set, Tuple


# -----------------------------------------------------------------------------
# Defaults
# -----------------------------------------------------------------------------
DEFAULT_EXCLUDE_DIR_NAMES: Set[str] = {
    ".git",
    "__pycache__",
    ".ipynb_checkpoints",
    "node_modules",
    ".venv",
    "venv",
    "dist",
    "build",
    ".mypy_cache",
    ".pytest_cache",
    ".ruff_cache",
    ".tox",
    ".idea",
    ".vscode",
    "coverage",
    "img",
    "images",
}

DEFAULT_EXCLUDE_FILE_NAMES: Set[str] = {
    ".DS_Store",
    "Thumbs.db",
    "package-lock.json",
    "yarn.lock",
    "pnpm-lock.yaml",
}

DEFAULT_EXCLUDE_GLOBS: Tuple[str, ...] = (
    "*.db",
    "*.sqlite",
    "*.sqlite3",
    "*.csv",
    "*.tsv",
    "*.parquet",
    "*.feather",
    "*.pkl",
    "*.pickle",
    "*.npz",
    "*.npy",
    "*.zip",
    "*.gz",
    "*.bz2",
    "*.7z",
    "*.pdf",
    "*.png",
    "*.jpg",
    "*.jpeg",
    "*.webp",
    "*.gif",
    "*.mp4",
    "*.mov",
    "*.avi",
    "*.wav",
    "*.mp3",
    "*.flac",
)

DEFAULT_INSTRUCTIONS = """\
=== AI INSTRUCTIONS (Generic) ===
You are given:
1) Project Tree: for understanding structure.
2) File Contents: each file begins with <<<FILE: path>>> and ends with <<<END FILE>>>.

Guidelines:
- Use any high-level descriptions or comments (if present) to understand structure and intent.
- Derive concrete behavior and details from the source files themselves.
- When descriptions and implementation differ, treat the implementation as the source of truth.
- When proposing changes, reference FILE_PATH and the relevant snippets.
===============================
"""


# -----------------------------------------------------------------------------
# Data models
# -----------------------------------------------------------------------------
class SkipReason(str, Enum):
    BINARY = "binary"
    TOO_BIG = "too_big"
    UNREADABLE = "unreadable"


@dataclass(frozen=True)
class Config:
    roots: Tuple[str, ...]
    out: str
    instructions_file: Optional[str]

    exclude_dir_names: Tuple[str, ...]
    exclude_file_names: Tuple[str, ...]
    exclude_path_substr: Tuple[str, ...]
    exclude_globs: Tuple[str, ...]
    exclude_paths: Tuple[str, ...]  # explicit paths (relative or absolute)

    tree_max_depth: int  # 0 = unlimited (also applies to traversal; kept for backward-compat)
    include_tree: bool

    max_bytes: int  # 0 = unlimited
    big_file: str  # "skip" or "truncate"
    truncate_bytes: int

    follow_symlinks: bool
    use_gitignore: bool
    no_binary_check: bool

    dry_run: bool


@dataclass
class FileDecision:
    path: str          # representative path (might be a symlink path)
    abs_path: str      # abspath of representative path
    uniq_key: str      # realpath if follow_symlinks else abspath

    included: bool
    reason: Optional[SkipReason] = None
    detail: Optional[str] = None

    read_bytes: Optional[int] = None  # None=full text read, else read first N bytes then decode
    truncated: bool = False


@dataclass(frozen=True)
class Candidate:
    """After excludes/.gitignore, before binary/size/readability checks."""
    rep_path: str
    abs_path: str
    uniq_key: str


# -----------------------------------------------------------------------------
# Utilities
# -----------------------------------------------------------------------------
def now_tokens() -> tuple[str, str]:
    dt = datetime.datetime.now()
    return dt.strftime("%Y%m%d"), dt.strftime("%H%M%S")


def expand_out_path(out: str) -> str:
    if out == "-":
        return out

    date_s, time_s = now_tokens()
    out2 = out.replace("{date}", date_s).replace("{time}", time_s)

    if out2.endswith(os.sep) or (os.path.exists(out2) and os.path.isdir(out2)):
        out_dir = out2[:-1] if out2.endswith(os.sep) else out2
        os.makedirs(out_dir, exist_ok=True)
        filename = f"bundletext_{date_s}_{time_s}.txt"
        return os.path.join(out_dir, filename)

    parent = os.path.dirname(out2)
    if parent:
        os.makedirs(parent, exist_ok=True)
    return out2


def norm_slash(p: str) -> str:
    return os.path.normpath(p).replace(os.sep, "/")


def dedup_preserve_order(items: Sequence[str]) -> List[str]:
    seen: Set[str] = set()
    out: List[str] = []
    for x in items:
        if not x:
            continue
        if x in seen:
            continue
        seen.add(x)
        out.append(x)
    return out


def uniq_key_for(path: str, follow_symlinks: bool) -> str:
    p = os.path.abspath(path)
    return os.path.realpath(p) if follow_symlinks else p


def rel_display_path(path: str, roots: Sequence[str]) -> str:
    norm = os.path.normpath(path)
    best = None
    for r in roots:
        r2 = os.path.normpath(r)
        if os.path.isdir(r2):
            try:
                rel = os.path.relpath(norm, r2)
                if not rel.startswith(".."):
                    cand = os.path.join(os.path.basename(r2) or r2, rel)
                    best = cand
                    break
            except Exception:
                pass
    disp = best if best else norm
    return disp.replace(os.sep, "/")


# -----------------------------------------------------------------------------
# Matching / exclusion helpers
# -----------------------------------------------------------------------------
def should_skip_by_substr(path: str, exclude_substrs: Sequence[str]) -> bool:
    norm = norm_slash(path)
    return any(s and s in norm for s in exclude_substrs)


def matches_any_glob(path: str, globs: Sequence[str]) -> bool:
    """
    Match against:
      - basename globs: *.db
      - path globs: **/data/**  (basic fnmatch, using normalized "/" path)
    """
    if not globs:
        return False
    p = norm_slash(path)
    base = os.path.basename(path)
    for g in globs:
        if not g:
            continue
        if fnmatch.fnmatch(base, g) or fnmatch.fnmatch(p, g):
            return True
    return False


def resolve_exclude_paths(exclude_paths: Sequence[str]) -> Set[str]:
    out: Set[str] = set()
    for raw in exclude_paths:
        if not raw:
            continue
        abs_p = os.path.abspath(raw)
        out.add(os.path.normpath(abs_p))
    return out


# -----------------------------------------------------------------------------
# Binary detection (UTF-8-first)
# -----------------------------------------------------------------------------
def probe_textiness(path: str, sample_size: int = 4096) -> Tuple[bool, Optional[str]]:
    """
    UTF-8-first heuristic (robust for Japanese text):

    - If NUL byte exists -> binary
    - If sample decodes as UTF-8 -> treat as text
    - Else fallback to "control-character ratio" heuristic

    Returns:
      (is_text, detail_if_binary_or_uncertain)
    Raises:
      OSError/IOError if the file can't be read at all (caller should classify as UNREADABLE).
    """
    with open(path, "rb") as f:
        sample = f.read(sample_size)

    if b"\x00" in sample:
        return False, "contains NUL byte(s)"
    if not sample:
        return True, None

    try:
        sample.decode("utf-8")
        return True, None
    except UnicodeDecodeError:
        pass

    ctrl = 0
    for b in sample:
        # allow tab(9), lf(10), cr(13)
        if b < 9 or (13 < b < 32):
            ctrl += 1
    ratio = (ctrl / len(sample))
    if ratio < 0.02:
        return True, None
    return False, f"control-char ratio={ratio:.3f} (>=0.02)"


# -----------------------------------------------------------------------------
# .gitignore (basic subset)
# -----------------------------------------------------------------------------
def read_gitignore_lines(gitignore_path: str) -> List[str]:
    try:
        with open(gitignore_path, "r", encoding="utf-8", errors="replace") as f:
            lines = []
            for line in f:
                s = line.strip()
                if not s or s.startswith("#"):
                    continue
                # NOTE: "!" negation not implemented in this basic version.
                if s.startswith("!"):
                    continue
                lines.append(s)
            return lines
    except Exception:
        return []


def gitignore_match(rel_path: str, patterns: Sequence[str]) -> bool:
    """
    Very small subset:
    - "foo/" matches directory prefix
    - "foo" matches file/dir name or path segment via fnmatch
    - patterns can contain globs
    - leading "/" anchors to root
    """
    p = rel_path.lstrip("./")
    p = p.replace("\\", "/")
    base = os.path.basename(p)

    for pat in patterns:
        anchored = pat.startswith("/")
        pat2 = pat[1:] if anchored else pat

        if pat2.endswith("/"):
            d = pat2[:-1]
            if anchored:
                if p == d or p.startswith(d + "/"):
                    return True
            else:
                if ("/" + d + "/") in ("/" + p + "/") or p.startswith(d + "/"):
                    return True
            continue

        if anchored:
            if fnmatch.fnmatch(p, pat2):
                return True
        else:
            if fnmatch.fnmatch(base, pat2) or fnmatch.fnmatch(p, f"**/{pat2}") or fnmatch.fnmatch(p, pat2):
                return True

    return False


def build_gitignore_cache(root_dir: str) -> Dict[str, List[str]]:
    """
    Map directory absolute path -> aggregated patterns applying to that directory.
    Aggregation rule:
      patterns(dir) = patterns(parent) + lines(dir/.gitignore)
    """
    cache: Dict[str, List[str]] = {}
    root_dir = os.path.abspath(root_dir)
    cache[root_dir] = []

    for cur, subdirs, _files in os.walk(root_dir):
        cur_abs = os.path.abspath(cur)
        if cur_abs not in cache:
            parent = os.path.dirname(cur_abs)
            cache[cur_abs] = list(cache.get(parent, []))

        gi = os.path.join(cur_abs, ".gitignore")
        if os.path.exists(gi) and os.path.isfile(gi):
            cache[cur_abs].extend(read_gitignore_lines(gi))

        for d in subdirs:
            child = os.path.abspath(os.path.join(cur_abs, d))
            if child not in cache:
                cache[child] = list(cache[cur_abs])

    return cache


def is_ignored_by_gitignore(path_abs: str, root_dir_abs: str, cache: Dict[str, List[str]]) -> bool:
    dir_abs = os.path.dirname(path_abs)
    patterns = cache.get(dir_abs, [])
    if not patterns:
        return False

    rel = os.path.relpath(path_abs, root_dir_abs).replace(os.sep, "/")
    if rel.startswith(".."):
        # outside root: don't apply gitignore rules
        return False
    return gitignore_match(rel, patterns)


# -----------------------------------------------------------------------------
# Traversal (candidates only; excludes + gitignore applied; binary/size later)
# -----------------------------------------------------------------------------
def iter_candidate_files_under_root(
    root: str,
    cfg: Config,
    exclude_dir_names: Set[str],
    exclude_file_names: Set[str],
    exclude_paths_abs: Set[str],
    gitignore_cache: Optional[Dict[str, List[str]]],
) -> Iterable[str]:
    """
    Yield candidate file paths after applying:
      - exclude-dir/file/glob/path/path-substr
      - gitignore (if enabled)

    Binary/size/unreadable checks are NOT done here.

    Symlinks:
      - followlinks=cfg.follow_symlinks
      - directory cycle protection via realpath visited set
      - file target de-dup per-root via realpath visited set
        (global de-dup is handled later with uniq_key_for)
    """
    root = os.path.normpath(root)
    if not os.path.exists(root):
        return

    visited_real_dirs: Set[str] = set()
    visited_real_files: Set[str] = set()

    if os.path.isfile(root):
        abs_p = os.path.abspath(root)
        if os.path.basename(root) in exclude_file_names:
            return
        if abs_p in exclude_paths_abs:
            return
        if should_skip_by_substr(abs_p, cfg.exclude_path_substr):
            return
        if matches_any_glob(abs_p, cfg.exclude_globs):
            return

        rk = uniq_key_for(abs_p, cfg.follow_symlinks)
        if cfg.follow_symlinks and rk in visited_real_files:
            return
        visited_real_files.add(rk)
        yield root
        return

    root_abs = os.path.abspath(root)

    for cur, subdirs, files in os.walk(root, followlinks=cfg.follow_symlinks):
        cur_abs = os.path.abspath(cur)

        # cycle protection for followed symlink dirs
        if cfg.follow_symlinks:
            cur_real = os.path.realpath(cur_abs)
            if cur_real in visited_real_dirs:
                subdirs[:] = []
                continue
            visited_real_dirs.add(cur_real)

        # traversal depth limit (kept as current behavior)
        if cfg.tree_max_depth > 0:
            rel = os.path.relpath(cur, root)
            depth = 0 if rel == "." else rel.count(os.sep) + 1
            if depth > cfg.tree_max_depth:
                subdirs[:] = []
                continue

        # exclude dir names
        subdirs[:] = [d for d in subdirs if d not in exclude_dir_names]

        # subtree excludes by substring/glob/path
        if should_skip_by_substr(cur_abs, cfg.exclude_path_substr):
            subdirs[:] = []
            continue
        if matches_any_glob(cur_abs, cfg.exclude_globs):
            subdirs[:] = []
            continue
        if cur_abs in exclude_paths_abs:
            subdirs[:] = []
            continue

        for fn in files:
            if fn in exclude_file_names:
                continue
            full = os.path.join(cur, fn)
            full_abs = os.path.abspath(full)

            if full_abs in exclude_paths_abs:
                continue
            if should_skip_by_substr(full_abs, cfg.exclude_path_substr):
                continue
            if matches_any_glob(full_abs, cfg.exclude_globs):
                continue

            if cfg.use_gitignore and gitignore_cache:
                if is_ignored_by_gitignore(full_abs, root_abs, gitignore_cache):
                    continue

            rk = uniq_key_for(full_abs, cfg.follow_symlinks)
            if cfg.follow_symlinks and rk in visited_real_files:
                continue
            visited_real_files.add(rk)

            yield full


# -----------------------------------------------------------------------------
# Planning (apply binary/size/unreadable, produce included vs skipped)
# -----------------------------------------------------------------------------
def decide_read_bytes_for_file(path: str, cfg: Config) -> Tuple[Optional[int], bool, bool]:
    """
    Returns:
      read_bytes: None => read full text; int => read first N bytes then decode as UTF-8
      will_skip: True if the file should be skipped due to size policy (big_file=skip)
      will_truncate: True if truncation will be applied
    """
    try:
        size = os.path.getsize(path)
    except Exception:
        size = -1

    if cfg.max_bytes > 0 and size >= 0 and size > cfg.max_bytes:
        if cfg.big_file == "skip":
            return None, True, False
        rb = cfg.truncate_bytes if cfg.truncate_bytes > 0 else cfg.max_bytes
        return rb, False, True

    return None, False, False


def collect_candidates(cfg: Config) -> Tuple[List[Candidate], Dict[str, Dict[str, List[str]]]]:
    """
    Collect candidates after excludes/.gitignore. Also performs global de-dup by uniq_key_for.

    Returns:
      candidates: sorted by representative path (stable)
      gitignore_caches: per directory root cache
    """
    exclude_dir_names = set(cfg.exclude_dir_names)
    exclude_file_names = set(cfg.exclude_file_names)
    exclude_paths_abs = resolve_exclude_paths(cfg.exclude_paths)

    gitignore_caches: Dict[str, Dict[str, List[str]]] = {}
    if cfg.use_gitignore:
        for r in cfg.roots:
            r_abs = os.path.abspath(r)
            if os.path.isdir(r_abs):
                gitignore_caches[r_abs] = build_gitignore_cache(r_abs)

    uniq_to_candidate: Dict[str, Candidate] = {}

    for r in cfg.roots:
        r_abs = os.path.abspath(r)
        gi_cache = gitignore_caches.get(r_abs)
        for fp in iter_candidate_files_under_root(
            r,
            cfg,
            exclude_dir_names,
            exclude_file_names,
            exclude_paths_abs,
            gi_cache,
        ):
            key = uniq_key_for(fp, cfg.follow_symlinks)
            if key in uniq_to_candidate:
                continue
            uniq_to_candidate[key] = Candidate(
                rep_path=fp,
                abs_path=os.path.abspath(fp),
                uniq_key=key,
            )

    candidates = sorted(uniq_to_candidate.values(), key=lambda c: c.rep_path)
    return candidates, gitignore_caches


def plan_files(cfg: Config) -> Tuple[List[FileDecision], List[str]]:
    """
    Returns:
      decisions: decisions for each candidate (one per unique target)
      candidate_abs: absolute paths for candidate tree (after excludes/.gitignore)
    """
    candidates, _gi = collect_candidates(cfg)
    candidate_abs = [c.abs_path for c in candidates]

    decisions: List[FileDecision] = []
    for c in candidates:
        rep = c.rep_path
        abs_p = c.abs_path
        key = c.uniq_key

        # 1) binary check (optional)
        if not cfg.no_binary_check:
            try:
                is_text, detail = probe_textiness(rep)
            except Exception as e:
                decisions.append(
                    FileDecision(
                        path=rep,
                        abs_path=abs_p,
                        uniq_key=key,
                        included=False,
                        reason=SkipReason.UNREADABLE,
                        detail=str(e),
                    )
                )
                continue

            if not is_text:
                decisions.append(
                    FileDecision(
                        path=rep,
                        abs_path=abs_p,
                        uniq_key=key,
                        included=False,
                        reason=SkipReason.BINARY,
                        detail=detail,
                    )
                )
                continue

        # 2) size policy
        read_bytes, will_skip, will_truncate = decide_read_bytes_for_file(rep, cfg)
        if will_skip:
            decisions.append(
                FileDecision(
                    path=rep,
                    abs_path=abs_p,
                    uniq_key=key,
                    included=False,
                    reason=SkipReason.TOO_BIG,
                    detail=f"size>{cfg.max_bytes} bytes",
                )
            )
            continue

        # 3) try-open check (permission / transient issues)
        try:
            if read_bytes is None:
                with open(rep, "r", encoding="utf-8", errors="replace") as f:
                    f.read(1)
            else:
                with open(rep, "rb") as f:
                    f.read(1)
        except Exception as e:
            decisions.append(
                FileDecision(
                    path=rep,
                    abs_path=abs_p,
                    uniq_key=key,
                    included=False,
                    reason=SkipReason.UNREADABLE,
                    detail=str(e),
                )
            )
            continue

        decisions.append(
            FileDecision(
                path=rep,
                abs_path=abs_p,
                uniq_key=key,
                included=True,
                read_bytes=read_bytes,
                truncated=bool(will_truncate),
            )
        )

    return decisions, candidate_abs


# -----------------------------------------------------------------------------
# Tree rendering (tree-only-included default)
# -----------------------------------------------------------------------------
def _insert_path(tree: dict, parts: List[str]) -> None:
    node = tree
    for p in parts[:-1]:
        node = node.setdefault("dirs", {}).setdefault(p, {})
    node.setdefault("files", set()).add(parts[-1])


def _render_tree(node: dict, depth: int, max_depth: int) -> List[str]:
    lines: List[str] = []
    if max_depth > 0 and depth > max_depth:
        return lines

    dirs = sorted(node.get("dirs", {}).keys())
    files = sorted(node.get("files", set()))

    indent = "    " * depth
    for d in dirs:
        if max_depth > 0 and depth >= max_depth:
            continue
        lines.append(f"{indent}{d}/")
        lines.extend(_render_tree(node["dirs"][d], depth + 1, max_depth))
    for f in files:
        lines.append(f"{indent}{f}")
    return lines


def build_tree_from_files(roots: Sequence[str], files_abs: Sequence[str], max_depth: int, title: str) -> str:
    """
    Build a simple tree from given absolute file paths under provided roots.
    """
    lines = [title]
    files_set = set(files_abs)  # perf

    for root in roots:
        root_norm = os.path.normpath(root)
        if not os.path.exists(root_norm):
            continue

        if os.path.isfile(root_norm):
            abs_root = os.path.abspath(root_norm)
            if abs_root in files_set:
                lines.append(os.path.basename(root_norm))
            continue

        root_abs = os.path.abspath(root_norm)
        lines.append(f"{os.path.basename(root_norm) or root_norm}/")

        rel_paths: List[str] = []
        for fp_abs in files_abs:
            try:
                rel = os.path.relpath(fp_abs, root_abs)
            except Exception:
                continue
            if rel.startswith(".."):
                continue
            rel_paths.append(rel)

        tree: dict = {}
        for rel in rel_paths:
            rel = os.path.normpath(rel)
            parts = [pp for pp in rel.split(os.sep) if pp and pp != "."]
            if parts:
                _insert_path(tree, parts)

        rendered = _render_tree(tree, depth=1, max_depth=max_depth if max_depth > 0 else 0)
        lines.extend(rendered)

    lines.append("====================\n")
    return "\n".join(lines)


def build_tree_from_included_files(roots: Sequence[str], included_abs: Sequence[str], max_depth: int) -> str:
    return build_tree_from_files(roots, included_abs, max_depth, "=== Project Tree ===")


# -----------------------------------------------------------------------------
# IO: instructions + bundle writing
# -----------------------------------------------------------------------------
def read_instructions(path: Optional[str]) -> str:
    if not path:
        return DEFAULT_INSTRUCTIONS
    try:
        with open(path, "r", encoding="utf-8") as f:
            return f.read().rstrip() + "\n"
    except Exception as e:
        return DEFAULT_INSTRUCTIONS + f"\n[Note: failed to read instructions file: {e}]\n"


def write_bundle(cfg: Config, decisions: Sequence[FileDecision]) -> int:
    out_path = expand_out_path(cfg.out)
    instructions = read_instructions(cfg.instructions_file)

    included = [d for d in decisions if d.included]
    included_abs = [d.abs_path for d in included]

    tree = ""
    if cfg.include_tree:
        tree = build_tree_from_included_files(cfg.roots, included_abs, cfg.tree_max_depth)

    if out_path == "-":
        out_f = sys.stdout
        close_after = False
    else:
        out_f = open(out_path, "w", encoding="utf-8")
        close_after = True

    count = 0
    truncated = 0

    try:
        out_f.write(instructions + "\n")
        if tree:
            out_f.write(tree + "\n")
        out_f.write("=== File Contents ===\n\n")

        for d in included:
            fp = d.path
            disp = rel_display_path(fp, cfg.roots)
            read_bytes = d.read_bytes

            try:
                out_f.write(f"\n<<<FILE: {disp}>>>\n")

                if read_bytes is None:
                    with open(fp, "r", encoding="utf-8", errors="replace") as f:
                        content = f.read()
                else:
                    with open(fp, "rb") as f:
                        b = f.read(read_bytes)
                    content = b.decode("utf-8", errors="replace")
                    content += "\n\n[TRUNCATED]\n"
                    truncated += 1

                out_f.write(content)
                if not content.endswith("\n"):
                    out_f.write("\n")
                out_f.write("<<<END FILE>>>\n")

                count += 1
            except Exception:
                # TOCTOU can happen; skip silently here.
                continue
    finally:
        if close_after:
            out_f.close()

    skipped_binary = sum(1 for d in decisions if (not d.included and d.reason == SkipReason.BINARY))
    skipped_big = sum(1 for d in decisions if (not d.included and d.reason == SkipReason.TOO_BIG))
    skipped_unreadable = sum(1 for d in decisions if (not d.included and d.reason == SkipReason.UNREADABLE))

    print(
        "bundletext: "
        f"wrote {count} file(s), "
        f"skipped_binary={skipped_binary}, skipped_big={skipped_big}, skipped_unreadable={skipped_unreadable}, "
        f"truncated={truncated}",
        file=sys.stderr,
    )
    if out_path != "-":
        print(f"bundletext: output={out_path}", file=sys.stderr)

    return count


# -----------------------------------------------------------------------------
# Dry-run report
# -----------------------------------------------------------------------------
def print_dry_run_report(cfg: Config, decisions: Sequence[FileDecision], candidate_abs: Sequence[str]) -> None:
    included = [d for d in decisions if d.included]
    skipped = [d for d in decisions if not d.included]

    included_abs = [d.abs_path for d in included]

    if cfg.include_tree:
        # Candidate Tree = after excludes/.gitignore (before binary/size/readability)
        cand_tree = build_tree_from_files(cfg.roots, candidate_abs, cfg.tree_max_depth, "=== Candidate Tree ===")
        print(cand_tree)

        # Project Tree = included-only (same as real output)
        tree = build_tree_from_included_files(cfg.roots, included_abs, cfg.tree_max_depth)
        print(tree)

    print("=== Dry Run: Included Files ===")
    if included:
        for d in included:
            disp = rel_display_path(d.path, cfg.roots)
            extra = ""
            if d.truncated:
                extra = f" [TRUNCATE to {d.read_bytes} bytes]"
            print(f"[OK] {disp}{extra}")
    else:
        print("(none)")
    print()

    print("=== Dry Run: Skipped Files ===")
    if skipped:
        for d in skipped:
            disp = rel_display_path(d.path, cfg.roots)
            detail = f" ({d.detail})" if d.detail else ""
            print(f"[SKIP:{d.reason}] {disp}{detail}")
    else:
        print("(none)")
    print()

    skipped_by_reason: Dict[str, int] = {}
    for d in skipped:
        k = str(d.reason)
        skipped_by_reason[k] = skipped_by_reason.get(k, 0) + 1

    print("=== Dry Run Summary ===")
    print(f"candidates(after excludes/gitignore): {len(candidate_abs)}")
    print(f"included: {len(included)}")
    print(f"skipped : {len(skipped)}")
    if skipped_by_reason:
        for k in sorted(skipped_by_reason.keys()):
            print(f"  - {k}: {skipped_by_reason[k]}")
    print("=======================\n")


# -----------------------------------------------------------------------------
# CLI parsing
# -----------------------------------------------------------------------------
def parse_args() -> Config:
    p = argparse.ArgumentParser(
        prog="bundletext",
        description="Bundle (mostly) all non-binary files under given paths into one text file.",
    )
    p.add_argument("paths", nargs="+", help="Root paths to include (directories and/or files).")

    p.add_argument(
        "-o",
        "--out",
        default="-",
        help="Output: FILE, DIR/, '-'(stdout), supports {date}/{time}. (ignored in --dry-run)",
    )
    p.add_argument("--instructions-file", default=None)

    # ADDITIVE excludes by default (built-ins are always applied)
    p.add_argument("--exclude-dir", nargs="*", default=[], help="Additional directory names to exclude (added to built-in defaults).")
    p.add_argument("--exclude-file", nargs="*", default=[], help="Additional file names to exclude (added to built-in defaults).")
    p.add_argument("--exclude-glob", nargs="*", default=[], help='Additional glob patterns to exclude (added to built-in defaults), e.g. "*.db" "**/data/**".')

    # switches to disable built-in excludes
    p.add_argument("--no-default-exclude-dir", action="store_true", help="Do not use built-in default excluded directories.")
    p.add_argument("--no-default-exclude-file", action="store_true", help="Do not use built-in default excluded files.")
    p.add_argument("--no-default-exclude-glob", action="store_true", help="Do not use built-in default excluded glob patterns.")

    p.add_argument("--exclude-path", nargs="*", default=[], help='Explicit paths to exclude (relative or absolute). e.g. "data/secret.txt" "tmp/".')
    p.add_argument("--exclude-path-substr", nargs="*", default=[])

    p.add_argument("--tree-max-depth", type=int, default=0)
    p.add_argument("--no-tree", action="store_true")

    p.add_argument("--max-bytes", type=int, default=0)
    p.add_argument("--big-file", choices=["skip", "truncate"], default="skip")
    p.add_argument("--truncate-bytes", type=int, default=0)

    p.add_argument("--follow-symlinks", action="store_true")
    p.add_argument("--no-gitignore", action="store_true", help="Disable reading .gitignore files (default: enabled).")

    p.add_argument(
        "--no-binary-check",
        action="store_true",
        help="Disable binary detection (treat all files as text; still subject to excludes and size policy).",
    )

    p.add_argument(
        "--dry-run",
        action="store_true",
        help="Do not write output. Print which files would be included/skipped (with reasons).",
    )

    a = p.parse_args()

    base_dirs = [] if a.no_default_exclude_dir else sorted(DEFAULT_EXCLUDE_DIR_NAMES)
    base_files = [] if a.no_default_exclude_file else sorted(DEFAULT_EXCLUDE_FILE_NAMES)
    base_globs = [] if a.no_default_exclude_glob else list(DEFAULT_EXCLUDE_GLOBS)

    merged_dirs = dedup_preserve_order(list(base_dirs) + list(a.exclude_dir))
    merged_files = dedup_preserve_order(list(base_files) + list(a.exclude_file))
    merged_globs = dedup_preserve_order(list(base_globs) + list(a.exclude_glob))

    return Config(
        roots=tuple(a.paths),
        out=a.out,
        instructions_file=a.instructions_file,
        exclude_dir_names=tuple(merged_dirs),
        exclude_file_names=tuple(merged_files),
        exclude_path_substr=tuple(a.exclude_path_substr),
        exclude_globs=tuple(merged_globs),
        exclude_paths=tuple(a.exclude_path),
        tree_max_depth=a.tree_max_depth,
        include_tree=(not a.no_tree),
        max_bytes=a.max_bytes,
        big_file=a.big_file,
        truncate_bytes=a.truncate_bytes,
        follow_symlinks=a.follow_symlinks,
        use_gitignore=(not a.no_gitignore),
        no_binary_check=bool(a.no_binary_check),
        dry_run=bool(a.dry_run),
    )


def main() -> None:
    cfg = parse_args()
    decisions, candidate_abs = plan_files(cfg)

    if cfg.dry_run:
        print_dry_run_report(cfg, decisions, candidate_abs)
        return

    write_bundle(cfg, decisions)


if __name__ == "__main__":
    main()
